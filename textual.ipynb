{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import lib to clear the news\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, GRU\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D, TimeDistributed, concatenate\n",
    "from keras.models import Model,Sequential\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TXT_DATA_FILE = 'data2/news/news_GOOGL.csv'\n",
    "NUM_DATA_FILE = 'data2/prices/stockPrices_GOOGL.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the number of words taken into consideration\n",
    "MAX_FEATURES = 20000\n",
    "# max lenght of one pieces of news\n",
    "MAX_LEN = 30\n",
    "# max number of news taken into consideration per day\n",
    "MAX_NEWS_NUM = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_df = pd.read_csv(TXT_DATA_FILE)\n",
    "txt_df['date'] = pd.to_datetime(txt_df['date'])\n",
    "txt_df.sort_values('date',inplace=True)\n",
    "txt_df = txt_df[txt_df['date'] < pd.Timestamp(2019,3,1)]\n",
    "txt_df = txt_df[txt_df['date'] >= pd.Timestamp(2016,1,1)]\n",
    "txt_df = txt_df.drop(['company'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_df = pd.read_csv(NUM_DATA_FILE)\n",
    "num_df['Date'] = pd.to_datetime(num_df['Date'])\n",
    "num_df.sort_values('Date',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# divide data in to three groups: test development train\n",
    "num_test = num_df[num_df['Date'] >= pd.Timestamp(2019,1,1)].values # test_set\n",
    "tmp = num_df[num_df['Date'] < pd.Timestamp(2019,1,1)]\n",
    "num_dev = tmp[tmp['Date'] >= pd.Timestamp(2018,9,1)].values # development_set\n",
    "num_train = tmp[tmp['Date'] < pd.Timestamp(2018,9,1)].values # train_set\n",
    "del tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4762, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1347</th>\n",
       "      <td>GOOGL</td>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>Ford  Toyota ally to counter Silicon Valley in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1346</th>\n",
       "      <td>GOOGL</td>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>GM invests $500 million in Lyft  sets out self...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345</th>\n",
       "      <td>GOOGL</td>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>Ford will expand self-driving test car fleet t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1344</th>\n",
       "      <td>GOOGL</td>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>German publishers have filed complaint against...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1343</th>\n",
       "      <td>GOOGL</td>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>Automakers  not Silicon Valley  lead in driver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1361</th>\n",
       "      <td>GOOGL</td>\n",
       "      <td>2016-01-06</td>\n",
       "      <td>Automakers strike back at Silicon Valley disru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1360</th>\n",
       "      <td>GOOGL</td>\n",
       "      <td>2016-01-06</td>\n",
       "      <td>Activist investor turns up heat on Yahoo  seek...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1362</th>\n",
       "      <td>GOOGL</td>\n",
       "      <td>2016-01-06</td>\n",
       "      <td>Coca-Cola blames ad agency for map showing Cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1357</th>\n",
       "      <td>GOOGL</td>\n",
       "      <td>2016-01-07</td>\n",
       "      <td>Renault-Nissan alliance plans self-driving car...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1358</th>\n",
       "      <td>GOOGL</td>\n",
       "      <td>2016-01-07</td>\n",
       "      <td>Mobileye wants automakers to share maps for au...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       code       date                                               text\n",
       "1347  GOOGL 2016-01-04  Ford  Toyota ally to counter Silicon Valley in...\n",
       "1346  GOOGL 2016-01-04  GM invests $500 million in Lyft  sets out self...\n",
       "1345  GOOGL 2016-01-05  Ford will expand self-driving test car fleet t...\n",
       "1344  GOOGL 2016-01-05  German publishers have filed complaint against...\n",
       "1343  GOOGL 2016-01-05  Automakers  not Silicon Valley  lead in driver...\n",
       "1361  GOOGL 2016-01-06  Automakers strike back at Silicon Valley disru...\n",
       "1360  GOOGL 2016-01-06  Activist investor turns up heat on Yahoo  seek...\n",
       "1362  GOOGL 2016-01-06  Coca-Cola blames ad agency for map showing Cri...\n",
       "1357  GOOGL 2016-01-07  Renault-Nissan alliance plans self-driving car...\n",
       "1358  GOOGL 2016-01-07  Mobileye wants automakers to share maps for au..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(txt_df.shape)\n",
    "txt_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAElCAYAAADp4+XfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlvt2rv+jkCwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f73b048e400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# count the number of news by date\n",
    "# in order to check the dense of news\n",
    "news_num_date = txt_df.groupby(txt_df['date']).count()\n",
    "attribute =  'text'\n",
    "plt.bar(news_num_date.index,news_num_date[attribute])\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('number')\n",
    "plt.show()\n",
    "del news_num_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clear news \n",
    "# remove non-word and lemmatize words\n",
    "def _clean_text(text):\n",
    "    lemma=WordNetLemmatizer()\n",
    "    text=str(text)\n",
    "    #text=re.sub('[^a-zA-Z\\-\\']', ' ',text)  # How to deal with 'NUMBER'?\n",
    "    #text=[lemma.lemmatize(w) for w in word_tokenize(text)]\n",
    "    text.replace('\\'s','') #!\n",
    "    text.replace('\\'','') #!\n",
    "    text=[lemma.lemmatize(w) for w in text.lower().split()]  # 词性还原\n",
    "    text=' '.join(text)\n",
    "    text=re.sub('[^a-zA-Z]', ' ' ,text) #!\n",
    "    return text\n",
    "\n",
    "def clean_news(df):\n",
    "    text = df['text']\n",
    "    text = _clean_text(text)\n",
    "    return text\n",
    "\n",
    "txt_df['text'] = txt_df.apply(clean_news, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# change the dataframe into dict\n",
    "# map: pd.Timestamp->news_group\n",
    "def df_to_dict(df):\n",
    "    news_group_dict = dict()\n",
    "    for index, row in df.iterrows():\n",
    "        if row['date'] not in news_group_dict:\n",
    "            news_group_dict[row['date']] = list()\n",
    "        news_group_dict[row['date']].append(row['text'])\n",
    "    \n",
    "    for key in news_group_dict:\n",
    "        blank = MAX_NEWS_NUM - len(news_group_dict[key])\n",
    "        if blank >= 0:\n",
    "            # need some blank\n",
    "            for _ in range(blank):\n",
    "                news_group_dict[key].append('')\n",
    "        else:\n",
    "            # need delete some elements\n",
    "            for _ in range(-blank):\n",
    "                # best is 'random'\n",
    "                news_group_dict[key].pop()    \n",
    "    return news_group_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# divide data in to three groups: test development train\n",
    "txt_test = df_to_dict(txt_df[txt_df['date'] >= pd.Timestamp(2019,1,1)]) # test_set\n",
    "tmp = txt_df[txt_df['date'] < pd.Timestamp(2019,1,1)] # ---bound---\n",
    "txt_dev = df_to_dict(tmp[tmp['date'] >= pd.Timestamp(2018,9,1)]) # development_set\n",
    "txt_train = df_to_dict(tmp[tmp['date'] < pd.Timestamp(2018,9,1)]) # train_set\n",
    "del tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change text into sequences with Keras\n",
    "tmp = txt_df[txt_df['date'] < pd.Timestamp(2019,1,1)]\n",
    "tk_train = tmp[tmp['date'] < pd.Timestamp(2018,9,1)]\n",
    "tokenizer = Tokenizer(num_words=MAX_FEATURES)\n",
    "tokenizer.fit_on_texts(list(tk_train['text']))\n",
    "del tmp,tk_train\n",
    "\n",
    "def _text_to_sequences(alist):\n",
    "    tokens = tokenizer.texts_to_sequences(alist)\n",
    "    seqs = pad_sequences(tokens,maxlen=MAX_LEN,truncating='post')\n",
    "    return seqs\n",
    "\n",
    "def text_to_sequences_by_day(adict):\n",
    "    # inplace\n",
    "    for (date,text_list) in adict.items():\n",
    "        adict[date] = _text_to_sequences(text_list)\n",
    "    return adict\n",
    "\n",
    "# overwrite\n",
    "txt_dev = text_to_sequences_by_day(txt_dev)\n",
    "txt_test = text_to_sequences_by_day(txt_test)\n",
    "text_train = text_to_sequences_by_day(txt_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_util import get_xy_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train) = get_xy_txt(txt_train,num_train)\n",
    "(x_test, y_test) = get_xy_txt(txt_test,num_test)\n",
    "(x_dev, y_dev) = get_xy_txt(txt_dev,num_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# the baseline of word embedding\n",
    "in the baseline, we just use the trained word vector matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use GloVe\n",
    "EMB_FILE = \"tool/GloVe/glove.42B.300d.txt\"\n",
    "#！can't use 840B\n",
    "def get_coefs(word,*arr):\n",
    "    return word,np.asarray(arr,dtype='float32')\n",
    "emb_index = dict(get_coefs(*o.strip().split()) for o in open(EMB_FILE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb_size=300\n",
    "all_embs = np.stack(emb_index.values())\n",
    "emb_mean = all_embs.mean()\n",
    "emb_std = all_embs.std()\n",
    "word_index = tokenizer.word_index\n",
    "hit_rate = 0\n",
    "ft_words = min(MAX_FEATURES,len(word_index))\n",
    "emb_matrix = np.random.normal(emb_mean,emb_std,(ft_words+1,emb_size))\n",
    "emb_matrix[0] = np.zeros(emb_size)  #！\n",
    "for word, i in word_index.items():\n",
    "    if i > ft_words:\n",
    "        continue\n",
    "    emb_vector = emb_index.get(word)\n",
    "    if emb_vector is not None:\n",
    "        hit_rate += 1\n",
    "        emb_matrix[i] = emb_vector\n",
    "hit_rate = hit_rate/ft_words\n",
    "print('Hit Rate is: ', hit_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb_model = Sequential()\n",
    "emb_model.add(Embedding(ft_words+1, emb_size, weights=[emb_matrix],trainable=False,\\\n",
    "                        input_shape = (DATE_INTERVAL,MAX_NEWS_NUM,MAX_LEN)))\n",
    "emb_model.compile('rmsprop', 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_dev = emb_model.predict(x_dev)\n",
    "x_test = emb_model.predict(x_test)\n",
    "x_train = emb_model.predict(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the baseline of news embedding\n",
    "in the baseline, we just add all word vectors in every news up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def news_embedding_baseline(x_data):\n",
    "    shape = x_data.shape\n",
    "    shape_dim = len(shape)\n",
    "    return np.mean(x_data,axis=shape_dim-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test = news_embedding_baseline(x_test)\n",
    "x_train = news_embedding_baseline(x_train)\n",
    "x_dev = news_embedding_baseline(x_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the baseline of importance recognition\n",
    "in th baseline, we just use RNN to get the representation of the news corpus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_baseline_model(code='Default'):\n",
    "    news_input = Input(shape=(DATE_INTERVAL,MAX_NEWS_NUM,emb_size))\n",
    "    day_layer = GRU(100, return_sequences=False)\n",
    "    day_layer = TimeDistributed(day_layer)\n",
    "    inv_layer = GRU(100, return_sequences=False)\n",
    "    x = day_layer(news_input)\n",
    "    x = inv_layer(x)\n",
    "    x = Dense(2,activation='softmax')(x)\n",
    "    model = Model(inputs=news_input,outputs=x)\n",
    "    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = build_baseline_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(x=x_train,y=y_train,batch_size=16,epochs=40,verbose=1,validation_data=(x_dev,y_dev))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
