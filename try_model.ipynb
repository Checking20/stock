{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Activation, GRU\n",
    "from keras.layers import Dropout, SpatialDropout1D\n",
    "from keras.layers import Bidirectional,TimeDistributed, concatenate\n",
    "from keras.layers import GlobalMaxPool1D, GlobalAvgPool1D, Masking\n",
    "from keras.models import Model,Sequential\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras import backend as K\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from process_data import load_data,get_rank_of_size\n",
    "from layers import AttentionLayer,MyMeanPool\n",
    "from callbacks import MetricsEx\n",
    "from data_util import unpack_news_data,DATE_INTERVAL_NEWS,MAX_NEWS_NUM,EMBEDDING_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rank = get_rank_of_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[rank[0]]['train'][0][0][0].toarray().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_generator(batch_size, x_data, y_data):\n",
    "    while True:\n",
    "        data_len = x_data.shape[0]\n",
    "        index_array = np.arange(data_len)\n",
    "        np.random.shuffle(index_array)\n",
    "        point = 0\n",
    "        while(point<x_data.shape[0]):\n",
    "            cur_batch_ids = index_array[point:min(point+batch_size,data_len)]\n",
    "            cur_batch_data = (unpack_news_data(x_data[cur_batch_ids]),y_data[cur_batch_ids])\n",
    "            point += batch_size\n",
    "            yield cur_batch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model(code='Default'):\n",
    "    news_input = Input(shape=(DATE_INTERVAL_NEWS,MAX_NEWS_NUM,EMBEDDING_SIZE))    \n",
    "    \n",
    "    x = news_input\n",
    "    x = TimeDistributed(Masking(mask_value=0.))(x)\n",
    "    x = TimeDistributed(AttentionLayer())(x)\n",
    "    x = TimeDistributed(Dropout(0.2))(x)\n",
    "    \n",
    "    x = GRU(100,return_sequences=True)(x)\n",
    "    x = AttentionLayer()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    x = Dense(2, activation='softmax')(x)\n",
    "    model = Model(inputs=news_input,outputs=x)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cbs = [TensorBoard(log_dir='model_log/'),MetricsEx('f1')]\n",
    "\n",
    "for i in range(1):\n",
    "    model.fit(x=unpack_news_data(data[rank[i]]['train'][0]),y=data[rank[i]]['train'][2],\n",
    "            batch_size=64,epochs=10,verbose=1,\n",
    "            validation_data=(unpack_news_data(data[rank[i]]['val'][0]),data[rank[i]]['val'][2]),\n",
    "            callbacks=cbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b_size = 32\n",
    "x_train = np.concatenate([data[key]['train'][0] for key in data],axis=0)\n",
    "y_train = np.concatenate([data[key]['train'][2] for key in data],axis=0)\n",
    "cbs = [TensorBoard(log_dir='model_log/'),MetricsEx('f1')]\n",
    "steps = (len(x_train)+b_size-1)//b_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(generator=data_generator(b_size,x_train,y_train),\n",
    "                    samples_per_epoch=steps,\n",
    "                    validation_data=(unpack_news_data(data['FB']['val'][0]),data['FB']['val'][2]),\n",
    "                    callbacks = cbs,\n",
    "                    epochs=2,\n",
    "                    verbose=1,\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.evaluate(x=unpack_news_data(data[rank[0]]['val'][0]), y=data[rank[0]]['val'][2],batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NUMERICAL MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numerical_timestep = 20 #  correspond to the 'size' of  the window\n",
    "attribute_num = 5 # Open/High/Low/AdjClose/Volume \n",
    "\n",
    "def build_numerical_model(code='Default'):\n",
    "    numerical_input = Input(shape=(numerical_timestep,attribute_num))\n",
    "    x = GRU(50,return_sequences=True)(numerical_input)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = GRU(50)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(10)(x)\n",
    "    x = Dense(2,activation='softmax')(x)\n",
    "    model = Model(inputs=numerical_input,outputs=x)\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nmodel = build_numerical_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(nmodel.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nmodel.fit(x=data[rank[0]]['train'][1],y=data[rank[0]]['train'][2],batch_size=16,epochs=100,verbose=2,\\\n",
    "          validation_data=(data[rank[0]]['val'][1],data[rank[0]]['val'][2]),\\\n",
    "          callbacks=[TensorBoard(log_dir='num_log/')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
