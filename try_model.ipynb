{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import sys\n",
    "import imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from process_data import load_data,get_rank_of_size\n",
    "from data_util import unpack_news_data,data_generator\n",
    "import models\n",
    "import callbacks\n",
    "imp.reload(models)\n",
    "imp.reload(callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rank = get_rank_of_size()\n",
    "rank.remove('XOM')\n",
    "rank.remove('GOOG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(rank[:1],encoder_kind='Bert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dd = data_generator(b_size,(x1_train,x2_train,y_train),unpack_news_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sparse matrix\n",
    "data[rank[0]]['train'][0][0][0].toarray().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEXTUAL MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.build_textual_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())\n",
    "plot_model(model, to_file='tmodel.png',show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b_size = 64\n",
    "x_train = np.concatenate([data[key]['train'][0] for key in data],axis=0)\n",
    "y_train = np.concatenate([data[key]['train'][2] for key in data],axis=0)\n",
    "x_val = unpack_news_data(np.concatenate([data[key]['val'][0] for key in data],axis=0))\n",
    "y_val = np.concatenate([data[key]['val'][2] for key in data],axis=0)\n",
    "cbs = [TensorBoard(log_dir='model_log/textual/')]\n",
    "steps = (len(x_train)+b_size-1)//b_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit_generator(generator=data_generator(b_size,(x_train,y_train),unpack_news_data),\n",
    "                    samples_per_epoch=steps,\n",
    "                    validation_data=(x_val,y_val),\n",
    "                    callbacks = cbs,\n",
    "                    epochs=20,\n",
    "                    verbose=1,\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NUMERICAL MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nmodel = models.build_numerical_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nmodel.summary())\n",
    "plot_model(nmodel, to_file='nmodel.png',show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b_size = 64\n",
    "x_train = np.concatenate([data[key]['train'][1] for key in data],axis=0)\n",
    "y_train = np.concatenate([data[key]['train'][2] for key in data],axis=0)\n",
    "x_val = np.concatenate([data[key]['val'][1] for key in data],axis=0)\n",
    "y_val = np.concatenate([data[key]['val'][2] for key in data],axis=0)\n",
    "cbs = [TensorBoard(log_dir='model_log/numerical/')]\n",
    "steps = (len(x_train)+b_size-1)//b_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nmodel.fit_generator(generator=data_generator(b_size,(x_train,y_train)),\n",
    "                    samples_per_epoch=steps,\n",
    "                    validation_data=(x_val,y_val),\n",
    "                    callbacks = cbs,\n",
    "                    epochs = 20,\n",
    "                    verbose=1,\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# HYBRID MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hmodel = models.build_hybrid_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hmodel.summary())\n",
    "plot_model(hmodel, to_file='hmodel.png',show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b_size = 64\n",
    "x1_train = np.concatenate([data[key]['train'][0] for key in data],axis=0)\n",
    "x2_train = np.concatenate([data[key]['train'][1] for key in data],axis=0)\n",
    "x1_val = unpack_news_data(np.concatenate([data[key]['val'][0] for key in data],axis=0))\n",
    "x2_val = np.concatenate([data[key]['val'][1] for key in data],axis=0)\n",
    "y_val = np.concatenate([data[key]['val'][2] for key in data],axis=0)\n",
    "y_train = np.concatenate([data[key]['train'][2] for key in data],axis=0)\n",
    "cbs = [TensorBoard(log_dir='num_log/hybrid/')]\n",
    "steps = (len(x1_train)+b_size-1)//b_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hmodel.fit_generator(generator=data_generator(b_size,(x1_train,x2_train,y_train),unpack_news_data),\n",
    "                    samples_per_epoch=steps,\n",
    "                    validation_data=([x1_val,x2_val],y_val),\n",
    "                    callbacks = cbs,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gmodel = models.build_guess_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = np.concatenate([np.random.randint(2, size=(data[key]['val'][2].shape[0],1)) for key in data])\n",
    "y_train = np.concatenate([data[key]['val'][2] for key in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gmodel.fit(x=x_train,y=y_train,verbose=1,epochs=30,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_dict = {}\n",
    "for code in rank[:20]:\n",
    "    result = hmodel.evaluate(x=[unpack_news_data(data[code]['test'][0]),data[code]['test'][1]],\n",
    "                             y=data[code]['test'][2],batch_size=32)\n",
    "    result_dict[code] = result[1]\n",
    "    if 'avg' not in result_dict:\n",
    "        result_dict['avg'] = 0\n",
    "    result_dict['avg'] += result[1]\n",
    "result_dict['avg'] /= 20\n",
    "print(result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
