{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Activation, GRU\n",
    "from keras.layers import Dropout, SpatialDropout1D\n",
    "from keras.layers import Bidirectional,TimeDistributed, concatenate\n",
    "from keras.layers import GlobalMaxPool1D, GlobalAvgPool1D, Masking\n",
    "from keras.models import Model,Sequential\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from process_data import load_data,get_rank_of_size\n",
    "from layers import AttentionLayer,MyMeanPool\n",
    "from data_util import unpack_news_data,DATE_INTERVAL_NEWS,MAX_NEWS_NUM,EMBEDDING_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rank = get_rank_of_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(rank[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['GOOGL']['train'][0][0][0].toarray().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_baseline_model(code='Default'):\n",
    "    news_input = Input(shape=(DATE_INTERVAL_NEWS,MAX_NEWS_NUM,EMBEDDING_SIZE))\n",
    "    inv_layer = GRU(100,return_sequences=True)\n",
    "    \n",
    "    x = news_input\n",
    "    x = TimeDistributed(Masking(mask_value=0.))(x)\n",
    "    x = TimeDistributed(SpatialDropout1D(0.1))(x)\n",
    "    x = TimeDistributed(AttentionLayer())(x)\n",
    "    \n",
    "    x = inv_layer(x)\n",
    "    x = SpatialDropout1D(0.2)(x)\n",
    "    x = AttentionLayer()(x)\n",
    "    \n",
    "    x = Dense(2, activation='softmax')(x)\n",
    "    model = Model(inputs=news_input,outputs=x)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_baseline_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    model.fit(x=unpack_news_data(data[rank[i]]['train'][0]),y=data[rank[i]]['train'][2],\n",
    "            batch_size=64,epochs=3,verbose=1,\n",
    "            validation_data=(unpack_news_data(data[rank[i]]['val'][0]),data[rank[i]]['val'][2]),\n",
    "            callbacks=[TensorBoard(log_dir='model_log/')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x=unpack_news_data(data[rank[0]]['val'][0]), y=data[rank[0]]['val'][2],batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NUMERICAL MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numerical_timestep = 20 #  correspond to the 'size' of  the window\n",
    "attribute_num = 5 # Open/High/Low/AdjClose/Volume \n",
    "\n",
    "def build_numerical_model(code='Default'):\n",
    "    numerical_input = Input(shape=(numerical_timestep,attribute_num))\n",
    "    x = GRU(50,return_sequences=True)(numerical_input)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = GRU(50)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(10)(x)\n",
    "    x = Dense(2,activation='softmax')(x)\n",
    "    model = Model(inputs=numerical_input,outputs=x)\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmodel = build_numerical_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nmodel.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmodel.fit(x=data[rank[0]]['train'][1],y=data[rank[0]]['train'][2],batch_size=16,epochs=100,verbose=2,\\\n",
    "          validation_data=(data[rank[0]]['val'][1],data[rank[0]]['val'][2]),\\\n",
    "          callbacks=[TensorBoard(log_dir='num_log/')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
