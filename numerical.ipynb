{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_DATA_FILE = 'data2/prices/stockPrices_GOOGL.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_df = pd.read_csv(NUM_DATA_FILE)\n",
    "num_df['Date'] = pd.to_datetime(num_df['Date'])\n",
    "num_df.sort_values('Date',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "attribute = 'Open'\n",
    "plt.plot(num_df[1000:]['Date'],num_df[1000:][attribute])\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel(attribute)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# divide data in to three groups\n",
    "num_test = num_df[num_df['Date'] >= pd.Timestamp(2019,1,1)].values # test_set\n",
    "tmp = num_df[num_df['Date'] < pd.Timestamp(2019,1,1)]\n",
    "num_dev = tmp[tmp['Date'] >= pd.Timestamp(2018,9,1)].values # development_set\n",
    "num_train = tmp[tmp['Date'] < pd.Timestamp(2018,9,1)].values # train_set\n",
    "del tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize the input data to make RNN work better\n",
    "def normalize(arr2d):\n",
    "    arr2d = arr2d.astype('float64')\n",
    "    n_arr2d = None\n",
    "    #for j in range(arr2d.shape[1]):\n",
    "        #scaler = MinMaxScaler(copy=True, feature_range=(0, 1))\n",
    "        #values = arr2d[:,j]\n",
    "        #values = values.reshape(-1,1)\n",
    "        #scaler.fit(values)\n",
    "        #if n_arr2d is None:\n",
    "            #n_arr2d = scaler.transform(values)\n",
    "        #else:\n",
    "            #n_arr2d = np.concatenate((n_arr2d,scaler.transform(values)),axis=1)\n",
    "            \n",
    "    # divide into two group: prices(Open,Low,High,adjClose) and volume\n",
    "    a_num = arr2d.shape[1]\n",
    "    p_scaler = MinMaxScaler(copy=True, feature_range=(0, 1))\n",
    "    p_values = arr2d[:,0:a_num-1].reshape(-1,1)\n",
    "    p_scaler.fit(p_values)\n",
    "    v_scaler = MinMaxScaler(copy=True, feature_range=(0, 1))\n",
    "    v_values = arr2d[:,a_num-1].reshape(-1,1)\n",
    "    v_scaler.fit(v_values)\n",
    "    for j in range(a_num):\n",
    "        scaler = p_scaler\n",
    "        if j == a_num-1:\n",
    "            scaler = v_scaler\n",
    "        values = arr2d[:,j]\n",
    "        values = values.reshape(-1,1)\n",
    "        if n_arr2d is None:\n",
    "            n_arr2d = scaler.transform(values)\n",
    "        else:\n",
    "            n_arr2d = np.concatenate((n_arr2d,scaler.transform(values)),axis=1)\n",
    "    return n_arr2d\n",
    "\n",
    "def get_x_by_sw(data_set,size=20):\n",
    "    # with sliding_window\n",
    "    data_dict = dict()\n",
    "    #including left but not right\n",
    "    left = right = 0\n",
    "    for i in range(len(data_set)):\n",
    "        if right>=left+size:\n",
    "            data_dict[data_set[right][0]] = \\\n",
    "            normalize(np.delete(data_set[left:right],[0,4],axis=1)) #remove 'Date' and 'Close'\n",
    "            left += 1\n",
    "        right += 1\n",
    "    return data_dict\n",
    "\n",
    "def get_y(data_set):\n",
    "    data_dict =dict()\n",
    "    len9 = len(data_set)\n",
    "    for i in range(len9):\n",
    "        if i > 0:\n",
    "            # How to define the change rate?\n",
    "            # Now set rate = open_price[1]/open_prices[i-1]-1\n",
    "            rate = data_set[i][1]/data_set[i-1][1]-1\n",
    "            if rate <=0:\n",
    "                data_dict[data_set[i][0]] = [1,0]\n",
    "            else:\n",
    "                data_dict[data_set[i][0]] = [0,1]\n",
    "    return data_dict\n",
    "\n",
    "def match_xy(x_dict,y_dict):\n",
    "    x_list = list()\n",
    "    y_list = list()\n",
    "    for key in x_dict.keys():\n",
    "        if key in y_dict:\n",
    "            x_list.append(x_dict[key])\n",
    "            y_list.append(y_dict[key])\n",
    "    x_arr = np.array(x_list)\n",
    "    y_arr = np.array(y_list)\n",
    "    return (x_arr,y_arr)\n",
    "\n",
    "def get_xy(data_set):\n",
    "    x_dict = get_x_by_sw(data_set)\n",
    "    y_dict = get_y(data_set)\n",
    "    return match_xy(x_dict,y_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(x_test,y_test) = get_xy(num_test)\n",
    "(x_train,y_train) = get_xy(num_train)\n",
    "(x_dev,y_dev) = get_xy(num_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, GRU\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D, TimeDistributed,concatenate\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numerical_timestep = 20 #  correspond to the 'size' of  the window\n",
    "attribute_num = 5 # Open/High/Low/AdjClose/Volume \n",
    "\n",
    "def build_model(code='Default'):\n",
    "    numerical_input = Input(shape=(numerical_timestep,attribute_num))\n",
    "    x = GRU(50,return_sequences=True)(numerical_input )\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = GRU(50)(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    # x = Dense(10)(x)\n",
    "    x = Dense(2,activation='softmax')(x)\n",
    "    model = Model(inputs=numerical_input,outputs=x)\n",
    "    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(x=x_train,y=y_train,batch_size=16,epochs=40,verbose=1,validation_data=(x_dev,y_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.evaluate(x=x_test,y=y_test,batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
